{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b52965",
   "metadata": {},
   "source": [
    "Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b0580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6935 files belonging to 2 classes.\n",
      "Training dataset prepared: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "Training dataset prepared: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6fafc",
   "metadata": {},
   "source": [
    "Part 1 - Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a24011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6935 files belonging to 2 classes.\n",
      "Training dataset prepared: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n",
      "Training dataset prepared: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation pipeline (applied to image tensors)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Helper to rescale pixel values to [0,1]\n",
    "rescale = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "# Load dataset from directory using the proper utility\n",
    "dataset_dir = r\"C:\\Users\\ladom\\Desktop\\LLm\\data\\dataset\\training_set\"\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(150, 150),\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Apply rescaling and augmentation to the dataset\n",
    "training_set = training_set.map(lambda x, y: (rescale(x), y))\n",
    "training_set = training_set.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# Prefetch for performance\n",
    "training_set = training_set.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Training dataset prepared:\", training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24fa58",
   "metadata": {},
   "source": [
    "preprocessing the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c98561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test set (do NOT apply augmentation here)\n",
    "testset_dir = r\"C:\\Users\\ladom\\Desktop\\LLm\\data\\dataset\\test_set\"\n",
    "\n",
    "# Create test dataset (no augmentation, no shuffling)\n",
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    testset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',    # match training label_mode\n",
    "    batch_size=32,\n",
    "    image_size=(150, 150),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Apply the SAME rescaling used for training (no augmentation)\n",
    "test_set = test_set.map(lambda x, y: (rescale(x), y))\n",
    "\n",
    "# Prefetch for performance\n",
    "test_set = test_set.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Test dataset prepared:\", test_set)\n",
    "print(\"Class names:\", test_set.class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
